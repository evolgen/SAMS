{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world!!!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello world!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Bio\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/18/ed1942f57e2748ab4805270ddd99df0aea47ab2b189b603017cb37dc9664/bio-1.3.2-py3-none-any.whl (272kB)\n",
      "\u001b[K     |████████████████████████████████| 276kB 29.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting mygene (from Bio)\n",
      "  Downloading https://files.pythonhosted.org/packages/a7/b7/132b1673c0ec00881d49d56c09624942fa0ebd2fc21d73d80647efa082e9/mygene-3.2.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: tqdm in /global/software/sl-7.x86_64/modules/langs/python/3.7/lib/python3.7/site-packages (from Bio) (4.36.1)\n",
      "Collecting biopython>=1.79 (from Bio)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/42/de1ed545df624180b84c613e5e4de4848f72989ce5846a74af6baa0737b9/biopython-1.79-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.3MB)\n",
      "\u001b[K     |████████████████████████████████| 2.3MB 54.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /global/software/sl-7.x86_64/modules/langs/python/3.7/lib/python3.7/site-packages (from Bio) (2.22.0)\n",
      "Collecting biothings-client>=0.2.6 (from mygene->Bio)\n",
      "  Downloading https://files.pythonhosted.org/packages/67/45/595faf22215de8d56900143572747357af67b48c62513383489a41b7d31a/biothings_client-0.2.6-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy in /global/software/sl-7.x86_64/modules/langs/python/3.7/lib/python3.7/site-packages (from biopython>=1.79->Bio) (1.17.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /global/software/sl-7.x86_64/modules/langs/python/3.7/lib/python3.7/site-packages (from requests->Bio) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /global/software/sl-7.x86_64/modules/langs/python/3.7/lib/python3.7/site-packages (from requests->Bio) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /global/software/sl-7.x86_64/modules/langs/python/3.7/lib/python3.7/site-packages (from requests->Bio) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /global/software/sl-7.x86_64/modules/langs/python/3.7/lib/python3.7/site-packages (from requests->Bio) (1.24.2)\n",
      "Installing collected packages: biothings-client, mygene, biopython, Bio\n",
      "\u001b[31mERROR: Could not install packages due to an EnvironmentError: [Errno 30] Read-only file system: '/global/software/sl-7.x86_64/modules/langs/python/3.7/lib/python3.7/site-packages/biothings_client-0.2.6.dist-info'\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pandas tabulate string re numpy collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATG\n",
      "ATC\n",
      "AGT\n",
      "AGC\n",
      "ACT\n",
      "ACG\n",
      "TAG\n",
      "TAC\n",
      "TGA\n",
      "TGC\n",
      "TCA\n",
      "TCG\n",
      "GAT\n",
      "GAC\n",
      "GTA\n",
      "GTC\n",
      "GCA\n",
      "GCT\n",
      "CAT\n",
      "CAG\n",
      "CTA\n",
      "CTG\n",
      "CGA\n",
      "CGT\n"
     ]
    }
   ],
   "source": [
    "# This is to create permutations of strings, here we are attempting permutate trinucleotides\n",
    "import itertools\n",
    "\n",
    "string_dna = \"ATGC\"\n",
    "\n",
    "trinuc_dnastring = list(itertools.permutations(string_dna, 3))\n",
    "\n",
    "for elem1 in trinuc_dnastring:\n",
    "    print(''.join(elem1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Bio'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-49277f960312>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mBio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mBio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPhylo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtabulate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtabulate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Bio'"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import Bio\n",
    "from Bio import Phylo\n",
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "\n",
    "import sized_slidingwindow\n",
    "\n",
    "def generate_pairs(self):\n",
    "    pairs = itertools.tee(self)\n",
    "    pairs[1].__next__()\n",
    "    return zip(pairs[0], pairs[1])\n",
    "\n",
    "def terminal_neighbor_dists(self):\n",
    "    \"\"\"Return a list of distances between adjacent terminals.\"\"\"\n",
    "    print(\"#species1\\tspecies2\\tdistance\")\n",
    "    for iname1 in generate_pairs(main_tree1.find_clades()):\n",
    "        if re.search('^Anc[0-9]+', iname1[0].name):\n",
    "            continue\n",
    "        print(iname1[0].name, iname1[1].name, main_tree1.distance(*iname1), sep=\"\\t\")\n",
    "#    return [self.distance(*i) for i in generate_pairs(self.find_clades(terminal=True))]\n",
    "\n",
    "def species_to_ancestor_sortdist_df(curr_tree_nwk_path):\n",
    "    main_tree1 = Phylo.read(curr_tree_nwk_path, \"newick\")\n",
    "    \n",
    "    terms = [term for term in main_tree1.get_terminals()]\n",
    "    list_terms1 = []\n",
    "    for curr1 in range(0,len(terms)-1):\n",
    "        list_terms1.append(terms[curr1].name)\n",
    "    \n",
    "    nonterms = [nonterm for nonterm in main_tree1.get_nonterminals()]\n",
    "    list_nonterms1 = []\n",
    "    for curr2 in range(0,len(nonterms)-1):\n",
    "        list_nonterms1.append(nonterms[curr2].name)\n",
    "        \n",
    "    dist_term_nonterm_all = []    \n",
    "    for curr_term1 in list_terms1:        \n",
    "        for curr_nonterm1 in list_nonterms1:\n",
    "            arr_curr_pair1 = [curr_term1, curr_nonterm1, main_tree1.distance(curr_term1,curr_nonterm1)]\n",
    "            dist_term_nonterm_all.append(arr_curr_pair1)\n",
    "            #print(curr_term1, curr_nonterm1, main_tree1.distance(curr_term1,curr_nonterm1), sep=\"\\t\")\n",
    "    \n",
    "    dist_term_nonterm_all = sorted(dist_term_nonterm_all, key=lambda x: (x[0], x[2]), reverse=False)\n",
    "    \n",
    "    return dist_term_nonterm_all\n",
    "    \n",
    "def conv_sp2ancdist_df2dict(df_dist_term_nonterm_df_pd):    \n",
    "    dist_term_nonterm_all_df = pd.DataFrame(df_dist_term_nonterm_df_pd, columns=['species1','species2','distance'], dtype=float)\n",
    "    \n",
    "    anc_species_anc_dict1 = dist_term_nonterm_all_df.groupby(['species1'])['species2'].agg({'species1': ','.join})['species1'].to_dict()\n",
    "\n",
    "    for anc_key1, anc_value1 in anc_species_anc_dict1.items():\n",
    "        anc_species_anc_dict1[anc_key1] = anc_value1.split(',')\n",
    "    \n",
    "    return anc_species_anc_dict1\n",
    "\n",
    "def initial_species_counter(anc_species_anc_dict1):\n",
    "    species_count_dict1 = {}\n",
    "\n",
    "    for key_elem1 in anc_species_anc_dict1.keys():\n",
    "        for pattern_elem2 in string_to_sized_combinations('ATGC',3):\n",
    "            species_count_dict1[key_elem1][pattern_elem2] = [0]\n",
    "    return species_count_dict1    \n",
    "    \n",
    "    \n",
    "main_tree1 = Phylo.read(\"/global/scratch2/rohitkolora/Rockfish/Genomes/alignments/cactus2/test/tree_seb77.nwk\", \"newick\")\n",
    "main_tree1_path = \"/global/scratch2/rohitkolora/Rockfish/Genomes/alignments/cactus2/test/tree_seb77.nwk\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Phylo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5c6316199556>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#species_to_ancestor_sortdist_df(main_tree1_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmain_tree1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPhylo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/global/scratch2/rohitkolora/Rockfish/Genomes/alignments/cactus2/test/tree_seb77.nwk\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"newick\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmain_tree1_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/global/scratch2/rohitkolora/Rockfish/Genomes/alignments/cactus2/test/tree_seb77.nwk\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Phylo' is not defined"
     ]
    }
   ],
   "source": [
    "#main_tree1_path\n",
    "\n",
    "#species_to_ancestor_sortdist_df(main_tree1_path)\n",
    "\n",
    "main_tree1 = Phylo.read(\"/global/scratch2/rohitkolora/Rockfish/Genomes/alignments/cactus2/test/tree_seb77.nwk\", \"newick\")\n",
    "main_tree1_path = \"/global/scratch2/rohitkolora/Rockfish/Genomes/alignments/cactus2/test/tree_seb77.nwk\"\n",
    "\n",
    "anc_species_anc_dict1 = conv_sp2ancdist_df2dict(species_to_ancestor_sortdist_df(main_tree1_path))\n",
    "\n",
    "species_count_dict1 = {}\n",
    "for pattern_elem2 in string_to_sized_combinations('ATGC',3):\n",
    "        species_count_dict1[pattern_elem2] = [0,0]\n",
    "\n",
    "species_count_dict2 = {}\n",
    "for key_elem1 in anc_species_anc_dict1.keys():\n",
    "        species_count_dict2[key_elem1] = species_count_dict1\n",
    "\n",
    "#print(species_count_dict2['Sebastes_alutus'])\n",
    "\n",
    "len(anc_species_anc_dict1)\n",
    "\n",
    "#initial_species_counter(conv_sp2ancdist_df2dict(species_to_ancestor_sortdist_df(main_tree1_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f0531700c5b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m df = pd.DataFrame([[1, 2, 3],\n\u001b[0m\u001b[1;32m      2\u001b[0m                    \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                    [3, 8, 9]],\n\u001b[1;32m      4\u001b[0m                   columns=['A', 'B', 'C'])\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'list'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame([[1, 2, 3],\n",
    "                   [2, 5, 6],\n",
    "                   [3, 8, 9]],\n",
    "                  columns=['A', 'B', 'C'])\n",
    "df.set_index(list(df)[0]).T.to_dict('list')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import string\n",
    "import re\n",
    "import bx.align.maf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "from optparse import OptionParser\n",
    "\n",
    "import sized_slidingwindow\n",
    "import species_info_fromtree\n",
    "import data_extract\n",
    "    \n",
    "#\n",
    "accepted_nucleotides = \"ATGCatgc\"\n",
    "\n",
    "#\n",
    "main_tree1_path = \"/global/scratch2/rohitkolora/Rockfish/Genomes/alignments/cactus2/test/tree_seb77.nwk\"\n",
    "\n",
    "#big_maffile1 = open(options.inputmaf, 'r')\n",
    "big_maffile1 = open('/global/scratch2/rohitkolora/Rockfish/Genomes/alignments/cactus2/test/small.maf', 'r')\n",
    "maf_reader1 = bx.align.maf.Reader(big_maffile1)\n",
    "\n",
    "#custom_species_list1 = open(options.specieslist, 'r') # Selected species list\n",
    "custom_species_list1 = open('/global/scratch2/rohitkolora/Rockfish/Genomes/traits/species_with_ages.list', 'r')\n",
    "custom_species_list1 = custom_species_list1.read().splitlines()\n",
    "\n",
    "# Extract ancestral info for species from tree\n",
    "species_to_ancestor_sortdist_df1 = species_info_fromtree.species_to_ancestor_sortdist_df(main_tree1_path)\n",
    "\n",
    "# Create df of species and ancestors\n",
    "anc_species_anc_dict1 = species_info_fromtree.conv_sp2ancdist_df2dict(species_to_ancestor_sortdist_df1)\n",
    "\n",
    "\n",
    "### Fun starts here\n",
    "# Create dict for counting transitions\n",
    "list_triplet_combinations = sized_slidingwindow.string_to_sized_combinations('ATGC',3)\n",
    "\n",
    "for key_elem1 in custom_species_list1: # anc_species_anc_dict1.keys(): # Creating nested dictionary of string patterns for each species\n",
    "        key_elem1 = str(key_elem1)\n",
    "        for pattern_elem2 in list_triplet_combinations: # Creating string pattern dictionary\n",
    "            pattern_elem2 = str(pattern_elem2)\n",
    "            for pattern_elem3 in list_triplet_combinations:\n",
    "                pattern_elem3 = str(pattern_elem3)\n",
    "                exec(f'{key_elem1}__{pattern_elem2}__{pattern_elem3} = 0')\n",
    "        \n",
    "        \n",
    "# Play with MAF blocks\n",
    "block_counter = 0\n",
    "for block_maf1 in maf_reader1: # We go block by block here - scope for parallelisation later\n",
    "    block_counter = block_counter + 1\n",
    "    block_now1 = pd.DataFrame(block_maf1.components) # creating df for the maf component\n",
    "\n",
    "    block_now2 = block_now1[0].apply(lambda x: pd.Series(str(x).split(\" \")))[[1,6]] # extracting seq header and sequence\n",
    "    block_now2.columns = [\"header\", \"sequence\"]\n",
    "    block_now2['species'] = block_now2['header'].apply(lambda x: pd.Series(str(x).split(\".\")))[[0]] # creating species names as column\n",
    "\n",
    "    sp_all1 = collections.Counter(block_now2['species'])\n",
    "    all_species_block_now2 = [i1 for i1,j1 in sp_all1.items() if j1==1] # Non redundant species alone\n",
    "\n",
    "    anc_species_block_now2 = [speciesname for speciesname in all_species_block_now2 if re.search('Anc[0-9]*$', speciesname)] # filtering for non ancestral alone\n",
    "\n",
    "    filt_species_block_now = [speciesname for speciesname in all_species_block_now2 if not re.search('Anc[0-9]*$', speciesname)] # filtering for non ancestral alone\n",
    "    filt_species_block_now2 = list(set(custom_species_list1) & set(filt_species_block_now)) # retaining only selected species\n",
    "\n",
    "    for curr_species1 in filt_species_block_now2: # Extracting data from tree\n",
    "        sequence_curr_species1 = data_extract.extract_sequence_4df(block_now2, curr_species1) # Extracting sequence for species\n",
    "\n",
    "        blocks_sequence_curr_species1 = sized_slidingwindow.create_list_slidingwindow(sequence_curr_species1,3)\n",
    "\n",
    "        curr_species_anc_list1 = anc_species_anc_dict1[curr_species1] # extract ancestral list for species\n",
    "        for anc_species1 in curr_species_anc_list1: # Iterating through anc. list for those in maf block\n",
    "            if anc_species1 not in anc_species_block_now2 or anc_species1 not in all_species_block_now2:\n",
    "                next\n",
    "            sequence_curr_ancestral1 = data_extract.extract_sequence_4df(block_now2, anc_species1) # Extracting sequence for species\n",
    "            break\n",
    "\n",
    "        blocks_sequence_curr_ancestral1 = sized_slidingwindow.create_list_slidingwindow(sequence_curr_ancestral1,3)\n",
    "\n",
    "        for count1 in range(0, len(blocks_sequence_curr_species1), 1):\n",
    "            curr_anc_nucl1 = blocks_sequence_curr_ancestral1[count1] # Storing ancestral pattern\n",
    "            curr_species_nucl1 = blocks_sequence_curr_species1[count1] # Storing species pattern\n",
    "\n",
    "            if all(nucl1 in accepted_nucleotides for nucl1 in curr_species_nucl1): # Checking for ATGCs alone\n",
    "                if all(nucl1 in accepted_nucleotides for nucl1 in curr_anc_nucl1):\n",
    "                    value_now1 = globals()[f'{curr_species1}__{curr_anc_nucl1}__{curr_species_nucl1}'] + 1\n",
    "                    exec(f'{curr_species1}__{curr_anc_nucl1}__{curr_species_nucl1} = value_now1')\n",
    "    \n",
    "    if(block_counter%25 == 0):\n",
    "        print(block_counter, end=\",\", flush=True)\n",
    "\n",
    "#final_species_counter1 = data_extract.counter_dict_conv_values(initial_species_counter1)    \n",
    "        \n",
    "#final_species_counter_df = data_extract.counter_dict_2_df(final_species_counter1)\n",
    "\n",
    "big_maffile1.close()\n",
    "\n",
    "print(\"Processed blocks :\", block_counter)\n",
    "initial_species_counter1 = {}\n",
    "species_count_dict1 = {}\n",
    "for key_elem1 in custom_species_list1: # anc_species_anc_dict1.keys(): # Creating nested dictionary of string patterns for each species\n",
    "        key_elem1 = str(key_elem1)\n",
    "        initial_species_counter1[key_elem1] = {}\n",
    "        for pattern_elem2 in list_triplet_combinations: # Creating string pattern dictionary\n",
    "            pattern_elem2 = str(pattern_elem2)\n",
    "            initial_species_counter1[key_elem1][pattern_elem2] = {}\n",
    "            for pattern_elem3 in list_triplet_combinations:\n",
    "                pattern_elem3 = str(pattern_elem3)\n",
    "                curr_value1 = int(globals()[f'{key_elem1}__{pattern_elem2}__{pattern_elem3}'])\n",
    "                initial_species_counter1[key_elem1][pattern_elem2][pattern_elem3] = curr_value1\n",
    "#                curr_value1 = str(globals()[f'{key_elem1}__{pattern_elem2}__{pattern_elem3}'])\n",
    "#                curr_string1 = key_elem1+\"__\"+pattern_elem2+\"__\"+pattern_elem3+\"__\"+ curr_value1\n",
    "                \n",
    "#                print(curr_string1.replace('__','\\t'), file=tsvfileout1)\n",
    "\n",
    "\n",
    "\n",
    "final_species_counter1 = data_extract.counter_dict_conv_values(initial_species_counter1)\n",
    "final_species_counter_df = data_extract.counter_dict_2_df(final_species_counter1)\n",
    "\n",
    "#tsvfileout1 = open('/global/scratch2/rohitkolora/Rockfish/Genomes/alignments/cactus2/test/outtest.tsv', 'w')\n",
    "#print(\"Species\\tPattern\\tTransition\\tCount\", file=tsvfileout1)\n",
    "\n",
    "#tsvfileout1.close()                \n",
    "\n",
    "print(\"Saved to output file too!!!\")\n",
    "\n",
    "final_species_counter_df.to_csv('/global/scratch2/rohitkolora/Rockfish/Genomes/alignments/cactus2/test/outsmall.tsv', sep='\\t', index=False) # Tab separated file\n",
    "#final_species_counter_df.to_csv('/global/scratch2/rohitkolora/Rockfish/Genomes/alignments/cactus2/test/output_mut_spectrum.tsv', sep='\\t', index=False) # Tab separated file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str3 = \"ATGC\"\n",
    "\n",
    "test1 = block_now2.loc[block_now2['species'] == curr_species1]['sequence']\n",
    "test2 = str(test1.values).replace('\\'','').replace('[','').replace(']','')\n",
    "print(test2)\n",
    "\n",
    "#sized_slidingwindow.create_list_slidingwindow(test2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import species_info_fromtree\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import hashlib\n",
    "import json\n",
    "\n",
    "main_tree1_path = \"/global/scratch2/rohitkolora/Rockfish/Genomes/alignments/cactus2/test/tree_seb55.nwk\"\n",
    "\n",
    "species_to_ancestor_sortdist_df1 = species_info_fromtree.species_to_ancestor_sortdist_df(main_tree1_path)\n",
    "\n",
    "#anc_species_anc_dict1 = species_info_fromtree.conv_sp2ancdist_df2dict(species_to_ancestor_sortdist_df1)\n",
    "\n",
    "dist_term_nonterm_all_df = pd.DataFrame(species_to_ancestor_sortdist_df1, columns=['species1','species2','distance'], dtype=float)\n",
    "    \n",
    "orig_anc_species_anc_dict1 = dist_term_nonterm_all_df.groupby(['species1'])['species2'].agg({'species1': ','.join})['species1'].to_dict()\n",
    "\n",
    "orig_md5 = hashlib.md5(json.dumps(orig_anc_species_anc_dict1).encode('utf-8')).hexdigest()\n",
    "\n",
    "print(orig_md5)\n",
    "print(orig_anc_species_anc_dict1['Sebastes_entomelas'])\n",
    "\n",
    "mod_anc_species_anc_dict1 = dist_term_nonterm_all_df.groupby(['species1'])['species2'].apply(','.join).to_dict()\n",
    "mod_md5 = hashlib.md5(json.dumps(mod_anc_species_anc_dict1).encode('utf-8')).hexdigest()\n",
    "\n",
    "print(mod_md5)\n",
    "print(mod_anc_species_anc_dict1['Sebastes_entomelas'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import string\n",
    "import re\n",
    "import bx.align.maf\n",
    "import pandas as pd\n",
    "import collections\n",
    "\n",
    "#parser = OptionParser(usage=\"usage: filter_maf_singlecopy.py -m large.maf\")\n",
    "#parser.add_option(\"-m\", \"--inputmaf\", action=\"store\", dest='inputmaf', type=\"string\")\n",
    "\n",
    "#(options, args) = parser.parse_args()\n",
    "\n",
    "#big_maffile1 = open(options.inputmaf, 'r')\n",
    "big_maffile1 = open('/global/scratch2/rohitkolora/Rockfish/Genomes/alignments/cactus2/test/test.maf', 'r')\n",
    "maf_reader1 = bx.align.maf.Reader(big_maffile1)\n",
    "\n",
    "print(\"##maf version=1\\n\")\n",
    "\n",
    "# Play with MAF blocks\n",
    "block_counter = 0\n",
    "for block_maf1 in maf_reader1: # We go block by block here - scope for parallelisation later\n",
    "    block_counter = block_counter + 1\n",
    "    block_now1 = pd.DataFrame(block_maf1.components) # creating df for the maf component\n",
    "    \n",
    "    block_now2 = block_now1[0].apply(lambda x: pd.Series(str(x).split(\" \")))[[1,6]] # extracting seq header and sequence\n",
    "    block_now2.columns = [\"header\", \"sequence\"]\n",
    "    block_now2['species'] = block_now2['header'].apply(lambda x: pd.Series(str(x).split(\".\")))[[0]] # creating species names as column\n",
    "    \n",
    "    sp_all1 = collections.Counter(block_now2['species'])    \n",
    "    single_species1 = [i1 for i1,j1 in sp_all1.items() if j1==1] # Getting single copy species\n",
    "    \n",
    "    start_single_species1 = [\"s \"+str1 for str1 in single_species1] # Modifying start for matching later\n",
    "\n",
    "    if len(single_species1) <= 1: # Filtering blocks with <2 single copy species in blocks \n",
    "        next\n",
    "    \n",
    "    print(\"a score=0\")\n",
    "    for lines1 in block_maf1.components:\n",
    "        test_truer = list(filter(str(lines1).startswith, start_single_species1)) != []\n",
    "        if test_truer:\n",
    "            print(str(lines1))#.replace(\" \",\"\\t\"))\n",
    "\n",
    "maf_reader1.close()            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(initial_species_counter1)\n",
    "#print(initial_species_counter1[\"Sebastes_dalli\"]['AAA']['AGA'])\n",
    "#print(initial_species_counter1[\"Sebastes_aleutianus\"]['AAA']['AGA'])\n",
    "#print(custom_species_list1)\n",
    "#initial_species_counter1_df = data_extract.counter_dict_2_df(initial_species_counter1)\n",
    "#initial_species_counter1_df.loc[(initial_species_counter1_df['Species']==curr_species1) & (initial_species_counter1_df['Pattern']==curr_anc_nucl1) & (initial_species_counter1_df['Transition']==curr_species_nucl1), 'Count'].index.values.astype(int)[0]  \n",
    "#initial_species_counter1_df.loc[57380,'Count']\n",
    "#initial_species_counter1_df.loc[:, [Species==curr_species1, Pattern==curr_anc_nucl1, Transition==curr_species_nucl1]]\n",
    "#initial_species_counter1_df[Species==curr_species1]\n",
    "#[curr_species1][curr_anc_nucl1][curr_species_nucl1]\n",
    "\n",
    "globals()[f'{key_elem1}__{pattern_elem2}__{pattern_elem3}'] + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "big_maffile1 = open('/global/scratch2/rohitkolora/Rockfish/Genomes/alignments/cactus2/test/small.maf', 'r')\n",
    "maf_reader1 = bx.align.maf.Reader(big_maffile1)\n",
    "\n",
    "list_triplet_combinations = sized_slidingwindow.string_to_sized_combinations('ATGC',3)\n",
    "\n",
    "#species_count_dict1 = collections.defaultdict(dict)\n",
    "for key_elem1 in custom_species_list1: # anc_species_anc_dict1.keys(): # Creating nested dictionary of string patterns for each species\n",
    "        key_elem1 = str(key_elem1)\n",
    "        for pattern_elem2 in list_triplet_combinations: # Creating string pattern dictionary\n",
    "#            species_count_dict1[pattern_elem2] = collections.defaultdict(dict)\n",
    "            pattern_elem2 = str(pattern_elem2)\n",
    "#            species_count_dict1 = {pattern_elem2: {}}\n",
    "            for pattern_elem3 in list_triplet_combinations:\n",
    "                pattern_elem3 = str(pattern_elem3)\n",
    "                exec(f'{key_elem1}__{pattern_elem2}__{pattern_elem3} = 0')\n",
    "#                print(pattern_elem2, pattern_elem3)\n",
    "        \n",
    "block_counter = 0\n",
    "for block_maf1 in maf_reader1: # We go block by block here - scope for parallelisation later\n",
    "#    print(\"15\",type(initial_species_counter1[\"Sebastes_dalli\"]['AAA']['AGA']))        \n",
    "    block_counter = block_counter + 1\n",
    "    block_now1 = pd.DataFrame(block_maf1.components) # creating df for the maf component\n",
    "\n",
    "    block_now2 = block_now1[0].apply(lambda x: pd.Series(str(x).split(\" \")))[[1,6]] # extracting seq header and sequence\n",
    "    block_now2.columns = [\"header\", \"sequence\"]\n",
    "    block_now2['species'] = block_now2['header'].apply(lambda x: pd.Series(str(x).split(\".\")))[[0]] # creating species names as column\n",
    "\n",
    "    sp_all1 = collections.Counter(block_now2['species'])\n",
    "    all_species_block_now2 = [i1 for i1,j1 in sp_all1.items() if j1==1] # Non redundant species alone\n",
    "\n",
    "    anc_species_block_now2 = [speciesname for speciesname in all_species_block_now2 if re.search('Anc[0-9]*$', speciesname)] # filtering for non ancestral alone\n",
    "\n",
    "    filt_species_block_now = [speciesname for speciesname in all_species_block_now2 if not re.search('Anc[0-9]*$', speciesname)] # filtering for non ancestral alone\n",
    "    filt_species_block_now2 = list(set(custom_species_list1) & set(filt_species_block_now)) # retaining only selected species\n",
    "\n",
    "    for curr_species1 in filt_species_block_now2: # Extracting data from tree\n",
    "        sequence_curr_species1 = data_extract.extract_sequence_4df(block_now2, curr_species1) # Extracting sequence for species\n",
    "\n",
    "        blocks_sequence_curr_species1 = sized_slidingwindow.create_list_slidingwindow(sequence_curr_species1,3)\n",
    "\n",
    "        curr_species_anc_list1 = anc_species_anc_dict1[curr_species1] # extract ancestral list for species\n",
    "        for anc_species1 in curr_species_anc_list1: # Iterating through anc. list for those in maf block\n",
    "            if anc_species1 not in anc_species_block_now2 or anc_species1 not in all_species_block_now2:\n",
    "                next\n",
    "            sequence_curr_ancestral1 = data_extract.extract_sequence_4df(block_now2, anc_species1) # Extracting sequence for species\n",
    "            break\n",
    "\n",
    "        blocks_sequence_curr_ancestral1 = sized_slidingwindow.create_list_slidingwindow(sequence_curr_ancestral1,3)\n",
    "\n",
    "        for count1 in range(0, len(blocks_sequence_curr_species1)):\n",
    "            curr_anc_nucl1 = blocks_sequence_curr_ancestral1[count1] # Storing ancestral pattern\n",
    "            curr_species_nucl1 = blocks_sequence_curr_species1[count1] # Storing species pattern\n",
    "\n",
    "            if all(nucl1 in accepted_nucleotides for nucl1 in curr_species_nucl1):\n",
    "                if all(nucl1 in accepted_nucleotides for nucl1 in curr_anc_nucl1): # Checking for ATGCs alone\n",
    "                    #curr_detail1 = print(f'{curr_species1}__{curr_anc_nucl1}__{curr_species_nucl1}')\n",
    "                    #value_now1 = print({curr_species1}__{curr_anc_nucl1}__{curr_species_nucl1})\n",
    "                    #value_now1 = globals()[f'{curr_detail1}'] + 1\n",
    "                    value_now1 = globals()[f'{curr_species1}__{curr_anc_nucl1}__{curr_species_nucl1}'] + 1\n",
    "                    exec(f'{curr_species1}__{curr_anc_nucl1}__{curr_species_nucl1} = value_now1')\n",
    "      \n",
    "                    \n",
    "    if(block_counter%25==0):\n",
    "        print(block_counter)\n",
    "\n",
    "big_maffile1.close()\n",
    "\n",
    "print(block_counter)\n",
    "\n",
    "#print(initial_species_counter1[\"Sebastes_dalli\"]['AAA']['AGA'])\n",
    "#print(initial_species_counter1[\"Sebastes_elongatus\"]['AAA']['AGA'])\n",
    "\n",
    "for key_elem1 in custom_species_list1: # anc_species_anc_dict1.keys(): # Creating nested dictionary of string patterns for each species\n",
    "        key_elem1 = str(key_elem1)\n",
    "        for pattern_elem2 in list_triplet_combinations: # Creating string pattern dictionary\n",
    "            pattern_elem2 = str(pattern_elem2)\n",
    "            for pattern_elem3 in list_triplet_combinations:\n",
    "                pattern_elem3 = str(pattern_elem3)\n",
    "                if(pattern_elem3==\"GTG\" and pattern_elem2==\"GTG\"):\n",
    "                    print(f'{key_elem1}__{pattern_elem2}__{pattern_elem3}', globals()[f'{key_elem1}__{pattern_elem2}__{pattern_elem3}'])\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25,50,75,Processed blocks : 76\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import string\n",
    "import re\n",
    "import bx.align.maf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import collections\n",
    "\n",
    "import sized_slidingwindow\n",
    "import species_info_fromtree\n",
    "import data_extract\n",
    "    \n",
    "#\n",
    "accepted_nucleotides = \"ATGCatgc\"\n",
    "\n",
    "#\n",
    "big_maffile1 = open('/global/scratch2/rohitkolora/Rockfish/Genomes/alignments/cactus2/test/small.maf', 'r')\n",
    "maf_reader1 = bx.align.maf.Reader(big_maffile1)\n",
    "\n",
    "main_tree1_path = \"/global/scratch2/rohitkolora/Rockfish/Genomes/alignments/cactus2/test/tree_seb77.nwk\"\n",
    "\n",
    "#custom_species_list1 = open(options.specieslist, 'r') # Selected species list\n",
    "custom_species_list1 = open('/global/scratch2/rohitkolora/Rockfish/Genomes/traits/species_with_ages.list', 'r')\n",
    "custom_species_list1 = custom_species_list1.read().splitlines()\n",
    "\n",
    "# Extract ancestral info for species from tree\n",
    "species_to_ancestor_sortdist_df1 = species_info_fromtree.species_to_ancestor_sortdist_df(main_tree1_path)\n",
    "\n",
    "# Create df of species and ancestors\n",
    "anc_species_anc_dict1 = species_info_fromtree.conv_sp2ancdist_df2dict(species_to_ancestor_sortdist_df1)\n",
    "for key1, value1 in anc_species_anc_dict1.items():\n",
    "    value1 = value1[0]\n",
    "    anc_species_anc_dict1[key1] = value1\n",
    "\n",
    "#    \n",
    "list_triplet_combinations = sized_slidingwindow.string_to_sized_combinations('ATGC',3)\n",
    "\n",
    "for key_elem1 in custom_species_list1: # anc_species_anc_dict1.keys(): # Creating nested dictionary of string patterns for each species\n",
    "        key_elem1 = str(key_elem1)\n",
    "        for pattern_elem2 in list_triplet_combinations: # Creating string pattern dictionary\n",
    "            pattern_elem2 = str(pattern_elem2)\n",
    "            for pattern_elem3 in list_triplet_combinations:\n",
    "                pattern_elem3 = str(pattern_elem3)\n",
    "                exec(f'{key_elem1}__{pattern_elem2}__{pattern_elem3} = 0')\n",
    "        \n",
    "        \n",
    "# Play with MAF blocks\n",
    "block_counter = 0\n",
    "for block_maf1 in maf_reader1: # We go block by block here - scope for parallelisation later\n",
    "    block_counter = block_counter + 1\n",
    "    block_now1 = pd.DataFrame(block_maf1.components) # creating df for the maf component\n",
    "\n",
    "    block_now2 = block_now1[0].apply(lambda x: pd.Series(str(x).split(\" \")))[[1,6]] # extracting seq header and sequence\n",
    "    block_now2.columns = [\"header\", \"sequence\"]\n",
    "    block_now2['species'] = block_now2['header'].apply(lambda x: pd.Series(str(x).split(\".\")))[[0]] # creating species names as column\n",
    "\n",
    "    sp_all1 = collections.Counter(block_now2['species'])\n",
    "    all_species_block_now2 = [i1 for i1,j1 in sp_all1.items() if j1==1] # Non redundant species alone\n",
    "\n",
    "    anc_species_block_now2 = [speciesname for speciesname in all_species_block_now2 if re.search('Anc[0-9]*$', speciesname)] # filtering for non ancestral alone\n",
    "\n",
    "    filt_species_block_now = [speciesname for speciesname in all_species_block_now2 if not re.search('Anc[0-9]*$', speciesname)] # filtering for non ancestral alone\n",
    "    filt_species_block_now2 = list(set(custom_species_list1) & set(filt_species_block_now)) # retaining only selected species\n",
    "\n",
    "    for curr_species1 in filt_species_block_now2: # Extracting data from tree\n",
    "        sequence_curr_species1 = data_extract.extract_sequence_4df(block_now2, curr_species1) # Extracting sequence for species\n",
    "\n",
    "        blocks_sequence_curr_species1 = sized_slidingwindow.create_list_slidingwindow(sequence_curr_species1,3)\n",
    "\n",
    "        curr_species_anc_list1 = anc_species_anc_dict1[curr_species1] # extract ancestral list for species\n",
    "        anc_species1 = curr_species_anc_list1\n",
    "        if anc_species1 not in anc_species_block_now2 or anc_species1 not in all_species_block_now2:\n",
    "            next\n",
    "        sequence_curr_ancestral1 = data_extract.extract_sequence_4df(block_now2, anc_species1) # Extracting sequence for species\n",
    "\n",
    "        blocks_sequence_curr_ancestral1 = sized_slidingwindow.create_list_slidingwindow(sequence_curr_ancestral1,3)\n",
    "\n",
    "        for count1 in range(0, len(blocks_sequence_curr_species1), 1):\n",
    "            curr_anc_nucl1 = blocks_sequence_curr_ancestral1[count1] # Storing ancestral pattern\n",
    "            curr_species_nucl1 = blocks_sequence_curr_species1[count1] # Storing species pattern\n",
    "\n",
    "            if all(nucl1 in accepted_nucleotides for nucl1 in curr_species_nucl1): # Checking for ATGCs alone\n",
    "                if all(nucl1 in accepted_nucleotides for nucl1 in curr_anc_nucl1):\n",
    "                    value_now1 = globals()[f'{curr_species1}__{curr_anc_nucl1}__{curr_species_nucl1}'] + 1\n",
    "                    exec(f'{curr_species1}__{curr_anc_nucl1}__{curr_species_nucl1} = value_now1')\n",
    "    \n",
    "    if(block_counter%25 == 0):\n",
    "        print(block_counter, end=\",\", flush=True)\n",
    "\n",
    "#final_species_counter1 = data_extract.counter_dict_conv_values(initial_species_counter1)    \n",
    "        \n",
    "#final_species_counter_df = data_extract.counter_dict_2_df(final_species_counter1)\n",
    "\n",
    "big_maffile1.close()\n",
    "\n",
    "print(\"Processed blocks :\", block_counter)\n",
    "initial_species_counter1 = {}\n",
    "species_count_dict1 = {}\n",
    "for key_elem1 in custom_species_list1: # anc_species_anc_dict1.keys(): # Creating nested dictionary of string patterns for each species\n",
    "        key_elem1 = str(key_elem1)\n",
    "        initial_species_counter1[key_elem1] = {}\n",
    "        for pattern_elem2 in list_triplet_combinations: # Creating string pattern dictionary\n",
    "            pattern_elem2 = str(pattern_elem2)\n",
    "            initial_species_counter1[key_elem1][pattern_elem2] = {}\n",
    "            for pattern_elem3 in list_triplet_combinations:\n",
    "                pattern_elem3 = str(pattern_elem3)\n",
    "                curr_value1 = int(globals()[f'{key_elem1}__{pattern_elem2}__{pattern_elem3}'])\n",
    "                initial_species_counter1[key_elem1][pattern_elem2][pattern_elem3] = curr_value1\n",
    "#                curr_value1 = str(globals()[f'{key_elem1}__{pattern_elem2}__{pattern_elem3}'])\n",
    "#                curr_string1 = key_elem1+\"__\"+pattern_elem2+\"__\"+pattern_elem3+\"__\"+ curr_value1\n",
    "                \n",
    "#                print(curr_string1.replace('__','\\t'), file=tsvfileout1)\n",
    "\n",
    "\n",
    "\n",
    "final_species_counter1 = data_extract.counter_dict_conv_values(initial_species_counter1)\n",
    "final_species_counter_df = data_extract.counter_dict_2_df(final_species_counter1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Anc71'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anc_species_anc_dict1[curr_species1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
